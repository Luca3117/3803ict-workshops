{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luca3117/3803ict-workshops/blob/main/Lab%208/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "b93f61f0-ce29-4ca5-bd27-87524a3263a2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "11fefb9e-4446-4fad-e9c2-7c2db01d7a1c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "outputId": "5c2fe6c4-609c-40ae-a7fb-50862f589a68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train / 255\n",
        "X_test_norm = X_test / 255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "outputId": "151003aa-6f71-4e5d-8413-8cd1c5ef7171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │            \u001b[38;5;34m60\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m48,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │        \u001b[38;5;34m10,164\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name=\"C5\"))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name=\"F6\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "0dae549e-72db-431d-ff00-4c8dee54fa0d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.3471 - loss: 1.9932 - val_accuracy: 0.6848 - val_loss: 0.8982\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7073 - loss: 0.8092 - val_accuracy: 0.7449 - val_loss: 0.6913\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7571 - loss: 0.6536 - val_accuracy: 0.7690 - val_loss: 0.6182\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7785 - loss: 0.5872 - val_accuracy: 0.7875 - val_loss: 0.5736\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7981 - loss: 0.5422 - val_accuracy: 0.8031 - val_loss: 0.5434\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8141 - loss: 0.5125 - val_accuracy: 0.8197 - val_loss: 0.5096\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8232 - loss: 0.4893 - val_accuracy: 0.8093 - val_loss: 0.5117\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8280 - loss: 0.4729 - val_accuracy: 0.8238 - val_loss: 0.4890\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8370 - loss: 0.4530 - val_accuracy: 0.8385 - val_loss: 0.4603\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8451 - loss: 0.4325 - val_accuracy: 0.8349 - val_loss: 0.4555\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8467 - loss: 0.4259 - val_accuracy: 0.8457 - val_loss: 0.4368\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8533 - loss: 0.4074 - val_accuracy: 0.8504 - val_loss: 0.4266\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8558 - loss: 0.4095 - val_accuracy: 0.8463 - val_loss: 0.4291\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8547 - loss: 0.4113 - val_accuracy: 0.8513 - val_loss: 0.4132\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8615 - loss: 0.3871 - val_accuracy: 0.8553 - val_loss: 0.4106\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8607 - loss: 0.3858 - val_accuracy: 0.8517 - val_loss: 0.4203\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8676 - loss: 0.3738 - val_accuracy: 0.8525 - val_loss: 0.4125\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8665 - loss: 0.3735 - val_accuracy: 0.8599 - val_loss: 0.3872\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8704 - loss: 0.3604 - val_accuracy: 0.8659 - val_loss: 0.3844\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8693 - loss: 0.3654 - val_accuracy: 0.8508 - val_loss: 0.4044\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8706 - loss: 0.3577 - val_accuracy: 0.8624 - val_loss: 0.3828\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8788 - loss: 0.3439 - val_accuracy: 0.8668 - val_loss: 0.3731\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8748 - loss: 0.3499 - val_accuracy: 0.8641 - val_loss: 0.3749\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8760 - loss: 0.3429 - val_accuracy: 0.8620 - val_loss: 0.3756\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8768 - loss: 0.3413 - val_accuracy: 0.8671 - val_loss: 0.3792\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8796 - loss: 0.3327 - val_accuracy: 0.8637 - val_loss: 0.3769\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8795 - loss: 0.3353 - val_accuracy: 0.8690 - val_loss: 0.3670\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8820 - loss: 0.3276 - val_accuracy: 0.8737 - val_loss: 0.3546\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8857 - loss: 0.3178 - val_accuracy: 0.8730 - val_loss: 0.3504\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8889 - loss: 0.3154 - val_accuracy: 0.8753 - val_loss: 0.3500\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8867 - loss: 0.3124 - val_accuracy: 0.8667 - val_loss: 0.3697\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8893 - loss: 0.3145 - val_accuracy: 0.8779 - val_loss: 0.3400\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8834 - loss: 0.3191 - val_accuracy: 0.8783 - val_loss: 0.3406\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8897 - loss: 0.3067 - val_accuracy: 0.8764 - val_loss: 0.3421\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8897 - loss: 0.3087 - val_accuracy: 0.8789 - val_loss: 0.3431\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8915 - loss: 0.3052 - val_accuracy: 0.8818 - val_loss: 0.3351\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8912 - loss: 0.3032 - val_accuracy: 0.8798 - val_loss: 0.3408\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8933 - loss: 0.3006 - val_accuracy: 0.8824 - val_loss: 0.3335\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8950 - loss: 0.2934 - val_accuracy: 0.8817 - val_loss: 0.3310\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.2898 - val_accuracy: 0.8849 - val_loss: 0.3284\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8960 - loss: 0.2874 - val_accuracy: 0.8817 - val_loss: 0.3312\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8943 - loss: 0.2953 - val_accuracy: 0.8855 - val_loss: 0.3250\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8975 - loss: 0.2839 - val_accuracy: 0.8854 - val_loss: 0.3251\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8992 - loss: 0.2852 - val_accuracy: 0.8850 - val_loss: 0.3261\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8964 - loss: 0.2919 - val_accuracy: 0.8835 - val_loss: 0.3284\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8985 - loss: 0.2830 - val_accuracy: 0.8839 - val_loss: 0.3257\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9019 - loss: 0.2765 - val_accuracy: 0.8775 - val_loss: 0.3501\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8986 - loss: 0.2824 - val_accuracy: 0.8837 - val_loss: 0.3248\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9014 - loss: 0.2756 - val_accuracy: 0.8806 - val_loss: 0.3353\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8990 - loss: 0.2787 - val_accuracy: 0.8820 - val_loss: 0.3327\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.2778 - val_accuracy: 0.8832 - val_loss: 0.3245\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8995 - loss: 0.2752 - val_accuracy: 0.8854 - val_loss: 0.3234\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9037 - loss: 0.2655 - val_accuracy: 0.8859 - val_loss: 0.3172\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9027 - loss: 0.2701 - val_accuracy: 0.8870 - val_loss: 0.3154\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9016 - loss: 0.2688 - val_accuracy: 0.8899 - val_loss: 0.3109\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9051 - loss: 0.2632 - val_accuracy: 0.8872 - val_loss: 0.3118\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9052 - loss: 0.2653 - val_accuracy: 0.8892 - val_loss: 0.3133\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9059 - loss: 0.2629 - val_accuracy: 0.8907 - val_loss: 0.3076\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9074 - loss: 0.2600 - val_accuracy: 0.8850 - val_loss: 0.3233\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9061 - loss: 0.2576 - val_accuracy: 0.8880 - val_loss: 0.3149\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9055 - loss: 0.2635 - val_accuracy: 0.8835 - val_loss: 0.3312\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9026 - loss: 0.2699 - val_accuracy: 0.8914 - val_loss: 0.3159\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9080 - loss: 0.2573 - val_accuracy: 0.8895 - val_loss: 0.3098\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9088 - loss: 0.2513 - val_accuracy: 0.8894 - val_loss: 0.3107\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9087 - loss: 0.2509 - val_accuracy: 0.8900 - val_loss: 0.3035\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9129 - loss: 0.2468 - val_accuracy: 0.8936 - val_loss: 0.3093\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.2549 - val_accuracy: 0.8948 - val_loss: 0.3038\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9090 - loss: 0.2508 - val_accuracy: 0.8934 - val_loss: 0.3055\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.2468 - val_accuracy: 0.8931 - val_loss: 0.3003\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9107 - loss: 0.2456 - val_accuracy: 0.8932 - val_loss: 0.3083\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9118 - loss: 0.2445 - val_accuracy: 0.8925 - val_loss: 0.3032\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9125 - loss: 0.2425 - val_accuracy: 0.8866 - val_loss: 0.3195\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9143 - loss: 0.2400 - val_accuracy: 0.8941 - val_loss: 0.3004\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9135 - loss: 0.2403 - val_accuracy: 0.8941 - val_loss: 0.3032\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9135 - loss: 0.2388 - val_accuracy: 0.8904 - val_loss: 0.3028\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9150 - loss: 0.2380 - val_accuracy: 0.8921 - val_loss: 0.3013\n",
            "Epoch 77/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9153 - loss: 0.2352 - val_accuracy: 0.8952 - val_loss: 0.2994\n",
            "Epoch 78/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9169 - loss: 0.2326 - val_accuracy: 0.8913 - val_loss: 0.3090\n",
            "Epoch 79/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9126 - loss: 0.2399 - val_accuracy: 0.8940 - val_loss: 0.3038\n",
            "Epoch 80/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9139 - loss: 0.2392 - val_accuracy: 0.8950 - val_loss: 0.2988\n",
            "Epoch 81/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9167 - loss: 0.2324 - val_accuracy: 0.8949 - val_loss: 0.3014\n",
            "Epoch 82/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9167 - loss: 0.2284 - val_accuracy: 0.8961 - val_loss: 0.2981\n",
            "Epoch 83/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9149 - loss: 0.2351 - val_accuracy: 0.8925 - val_loss: 0.3012\n",
            "Epoch 84/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9161 - loss: 0.2280 - val_accuracy: 0.8941 - val_loss: 0.3024\n",
            "Epoch 85/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9161 - loss: 0.2306 - val_accuracy: 0.8962 - val_loss: 0.2939\n",
            "Epoch 86/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9186 - loss: 0.2226 - val_accuracy: 0.8948 - val_loss: 0.2964\n",
            "Epoch 87/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9178 - loss: 0.2278 - val_accuracy: 0.8956 - val_loss: 0.2961\n",
            "Epoch 88/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9192 - loss: 0.2245 - val_accuracy: 0.8989 - val_loss: 0.2965\n",
            "Epoch 89/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9205 - loss: 0.2204 - val_accuracy: 0.8932 - val_loss: 0.3001\n",
            "Epoch 90/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9185 - loss: 0.2235 - val_accuracy: 0.8946 - val_loss: 0.2953\n",
            "Epoch 91/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9191 - loss: 0.2221 - val_accuracy: 0.8950 - val_loss: 0.3001\n",
            "Epoch 92/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.2208 - val_accuracy: 0.8915 - val_loss: 0.3126\n",
            "Epoch 93/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9182 - loss: 0.2237 - val_accuracy: 0.8955 - val_loss: 0.3022\n",
            "Epoch 94/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 0.2218 - val_accuracy: 0.8992 - val_loss: 0.2907\n",
            "Epoch 95/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.2155 - val_accuracy: 0.8945 - val_loss: 0.3014\n",
            "Epoch 96/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.2152 - val_accuracy: 0.8964 - val_loss: 0.2978\n",
            "Epoch 97/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.2154 - val_accuracy: 0.8950 - val_loss: 0.2967\n",
            "Epoch 98/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9206 - loss: 0.2144 - val_accuracy: 0.8977 - val_loss: 0.2971\n",
            "Epoch 99/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.2144 - val_accuracy: 0.8971 - val_loss: 0.2927\n",
            "Epoch 100/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9241 - loss: 0.2094 - val_accuracy: 0.8954 - val_loss: 0.2925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aff58b8b9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "cb0d0551-9106-4356-c218-41777a844a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "accuracy on train with CNN: 0.9246166666666666\n",
            "accuracy on test with CNN: 0.8954\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter:\n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "e70c1429-8421-400e-b3fe-d934c8cd478f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.9383 - loss: 0.1674 - val_accuracy: 0.9035 - val_loss: 0.2832\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9316 - loss: 0.1837 - val_accuracy: 0.9015 - val_loss: 0.2879\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9343 - loss: 0.1760 - val_accuracy: 0.9051 - val_loss: 0.2836\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9385 - loss: 0.1663 - val_accuracy: 0.9056 - val_loss: 0.2808\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9390 - loss: 0.1673 - val_accuracy: 0.9024 - val_loss: 0.2852\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.1599 - val_accuracy: 0.9018 - val_loss: 0.2844\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9387 - loss: 0.1661 - val_accuracy: 0.9009 - val_loss: 0.2866\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9316 - loss: 0.1685 - val_accuracy: 0.9042 - val_loss: 0.2805\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9378 - loss: 0.1689 - val_accuracy: 0.9046 - val_loss: 0.2822\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9453 - loss: 0.1523 - val_accuracy: 0.9035 - val_loss: 0.2876\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9393 - loss: 0.1671 - val_accuracy: 0.9037 - val_loss: 0.2902\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9395 - loss: 0.1470 - val_accuracy: 0.9056 - val_loss: 0.2850\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9382 - loss: 0.1689 - val_accuracy: 0.9024 - val_loss: 0.2901\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9365 - loss: 0.1544 - val_accuracy: 0.9048 - val_loss: 0.2851\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9412 - loss: 0.1615 - val_accuracy: 0.9045 - val_loss: 0.2934\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9307 - loss: 0.1773 - val_accuracy: 0.9038 - val_loss: 0.2946\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9392 - loss: 0.1617 - val_accuracy: 0.9037 - val_loss: 0.2894\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9258 - loss: 0.2165 - val_accuracy: 0.9045 - val_loss: 0.2903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7affd7099850>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) // batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "e2dd8638-6419-4aff-886b-c18b3e1e7d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "accuracy on train with CNN: 0.9421666666666667\n",
            "accuracy on test with CNN: 0.9045\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01-LeNet5-solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}