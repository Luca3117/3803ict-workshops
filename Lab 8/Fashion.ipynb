{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL2afF5MiigW"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etAzLjZ6iiga"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqjLc_2Niigb"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "id": "4TG1Hcpeiigb",
        "outputId": "07c36ab7-65c0-4276-9a0c-5504d01b2359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "# X_test = ...\n",
        "# y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Et9NLDiigd"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e50TL2S-iige"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "6ruzCRlfiige",
        "outputId": "d06f24ff-a9e6-4118-b6da-28339bfb408b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiXVu33Ziige"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-TWHqBGiige"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtFJb0rPiigf"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Iwc3TEKbiigf"
      },
      "outputs": [],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train / 255\n",
        "X_test_norm = X_test / 255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRdtxok2iigf"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uOXbxF2Siigf",
        "outputId": "5cc74853-8a75-4b49-aa60-7181f4901542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,070\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,070</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,070\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,070</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation=\"sigmoid\"))\n",
        "    model.add(Dense(10, activation=\"sigmoid\"))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVMiDh9giigf"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "t0ZCI6ATiigf",
        "outputId": "2a6677a4-17fb-4e59-f312-01bf039ed729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2826 - loss: 2.0976\n",
            "Epoch 2/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6154 - loss: 1.4196\n",
            "Epoch 3/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 1.0137\n",
            "Epoch 4/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.8180\n",
            "Epoch 5/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.6733\n",
            "Epoch 6/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5834\n",
            "Epoch 7/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.5314\n",
            "Epoch 8/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4954\n",
            "Epoch 9/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.4666\n",
            "Epoch 10/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.4536\n",
            "Epoch 11/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4371\n",
            "Epoch 12/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4211\n",
            "Epoch 13/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.4165\n",
            "Epoch 14/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.4022\n",
            "Epoch 15/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.3989\n",
            "Epoch 16/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3946\n",
            "Epoch 17/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3916\n",
            "Epoch 18/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8620 - loss: 0.3906\n",
            "Epoch 19/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.3789\n",
            "Epoch 20/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3731\n",
            "Epoch 21/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3683\n",
            "Epoch 22/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.3699\n",
            "Epoch 23/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3624\n",
            "Epoch 24/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3607\n",
            "Epoch 25/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.3571\n",
            "Epoch 26/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.3570\n",
            "Epoch 27/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.3504\n",
            "Epoch 28/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.3522\n",
            "Epoch 29/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.3483\n",
            "Epoch 30/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3489\n",
            "Epoch 31/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3470\n",
            "Epoch 32/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3437\n",
            "Epoch 33/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.3430\n",
            "Epoch 34/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3351\n",
            "Epoch 35/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3364\n",
            "Epoch 36/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.3354\n",
            "Epoch 37/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3331\n",
            "Epoch 38/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3388\n",
            "Epoch 39/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.3388\n",
            "Epoch 40/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3315\n",
            "Epoch 41/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.3312\n",
            "Epoch 42/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3316\n",
            "Epoch 43/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.3279\n",
            "Epoch 44/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3250\n",
            "Epoch 45/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.3309\n",
            "Epoch 46/100\n",
            "\u001b[1m 44/469\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3225"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bO3mgNBiigg"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhnoNRwfiigg"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svNooo-Yiigg"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRjcrSOZiigg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gBWlEBfiigg"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR_Q7Hsviigh"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEAjqXvriigh"
      },
      "outputs": [],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHe-6oNBiigh"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AxBed_YCGq39"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJaNZzPOiigh"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}